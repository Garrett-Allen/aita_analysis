{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33547,"sourceType":"modelInstanceVersion","modelInstanceId":28079},{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-29T14:53:29.270429Z","iopub.execute_input":"2024-04-29T14:53:29.271077Z","iopub.status.idle":"2024-04-29T14:53:30.550043Z","shell.execute_reply.started":"2024-04-29T14:53:29.271041Z","shell.execute_reply":"2024-04-29T14:53:30.549075Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-3/transformers/8b-hf/1/model.safetensors.index.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00003-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/LICENSE\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00001-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/USE_POLICY.md\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer.json\n/kaggle/input/llama-3/transformers/8b-hf/1/tokenizer_config.json\n/kaggle/input/llama-3/transformers/8b-hf/1/example_text_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/requirements.txt\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00004-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/eval_details.md\n/kaggle/input/llama-3/transformers/8b-hf/1/special_tokens_map.json\n/kaggle/input/llama-3/transformers/8b-hf/1/model-00002-of-00004.safetensors\n/kaggle/input/llama-3/transformers/8b-hf/1/example_chat_completion.py\n/kaggle/input/llama-3/transformers/8b-hf/1/setup.py\n/kaggle/input/llama-3/transformers/8b-hf/1/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport transformers\nimport torch\n\nmodel = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n# model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model)\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:03:35.119977Z","iopub.execute_input":"2024-04-29T15:03:35.120348Z","iopub.status.idle":"2024-04-29T15:05:53.528199Z","shell.execute_reply.started":"2024-04-29T15:03:35.120312Z","shell.execute_reply":"2024-04-29T15:05:53.527198Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n2024-04-29 15:03:44.489942: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 15:03:44.490060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 15:03:44.643308: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02fcc3add2c4ca6b54ca0bee3a91963"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences = pipeline(\n    'I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\\n',\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_length=200,\n)\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:05:53.529967Z","iopub.execute_input":"2024-04-29T15:05:53.530737Z","iopub.status.idle":"2024-04-29T15:06:08.024990Z","shell.execute_reply.started":"2024-04-29T15:05:53.530699Z","shell.execute_reply":"2024-04-29T15:06:08.024027Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Result: I liked \"Breaking Bad\" and \"Band of Brothers\". Do you have any recommendations of other shows I might like?\nI would say The Wire, The Sopranos, Mad Men (I know you don't like period dramas, but if you can get past that, it's great). And I would highly recommend Game of Thrones, though you might want to wait for the next season to end before you watch it, since the show has a habit of ending on cliffhangers at the end of each season.\nI'm sure I can find something on my computer, but it might take a while.\nThanks. I will check those out, although I don't watch Mad Men or Game of Thrones.\nMad Men is definitely worth trying. It's really, really good. I'm not sure about Game of Thrones. I've watched up until S3 and it's not bad, but the S2 cliffhanger was really annoying and the show has a tendency to focus on the characters\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:35:19.008771Z","iopub.execute_input":"2024-04-29T15:35:19.009123Z","iopub.status.idle":"2024-04-29T15:35:19.015509Z","shell.execute_reply.started":"2024-04-29T15:35:19.009098Z","shell.execute_reply":"2024-04-29T15:35:19.014547Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"128001"},"metadata":{}}]},{"cell_type":"code","source":"pipeline.tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:35:25.697402Z","iopub.execute_input":"2024-04-29T15:35:25.698373Z","iopub.status.idle":"2024-04-29T15:35:25.705108Z","shell.execute_reply.started":"2024-04-29T15:35:25.698331Z","shell.execute_reply":"2024-04-29T15:35:25.704032Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"128001"},"metadata":{}}]},{"cell_type":"code","source":"sequences = pipeline(\n    'What is the capital of japan?\\n',\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_length=200,\n)\n\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:38:44.579185Z","iopub.execute_input":"2024-04-29T15:38:44.579904Z","iopub.status.idle":"2024-04-29T15:38:57.910474Z","shell.execute_reply.started":"2024-04-29T15:38:44.579874Z","shell.execute_reply":"2024-04-29T15:38:57.909521Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Result: What is the capital of japan?\nIs there a Japanese embassy in Australia?\nYes - it's in Canberra. You could also visit their official web site: japanembassy.org.au/eng/.\nWhere can I buy a cheap car in Japan?\nWhat is the population of Tokyo?\nWhere can I find cheap car hire in Japan?\nThere are lots of companies that provide car rental in Japan. You can check prices and availability at www.rentalcarguide.com or www.carhire.com.\nWhat time is it in Tokyo?\nTokyo is nine hours ahead of Greenwich Mean Time (GMT).\nWhat's the best time visit Japan?\nThe spring is a good time to visit Japan if you're looking for the flowers in blossom (the'sakura' or cherry blossom season). The summer months are very hot and humid and the typhoons in the southern areas can be dangerous. Winter can bring snow in the northern regions of the country. It's also a good idea to take care if you're\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences = pipeline(\n    'What is the capital of japan?\\n',\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_length=256,\n)\n\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:25.699089Z","iopub.execute_input":"2024-04-29T15:37:25.699489Z","iopub.status.idle":"2024-04-29T15:37:33.735523Z","shell.execute_reply.started":"2024-04-29T15:37:25.699454Z","shell.execute_reply":"2024-04-29T15:37:33.734573Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Result: What is the capital of japan?\nIs the capital of Japan is a large city located on the island of Honshu?\nWhat is the capital of Japan and is it a large city located on the Honshu Island?\nThe capital city of Japan is Tokyo, and it is a large city located on the island of Honshu.\nWhat are capital of Japan?\nTokyo is the capital of Japan.\nWhat is the capitol of Japan?\nWhat is the capital of Japan? What is the capital of Japan?\nWhat is Tokyo capital of japan?\nWhat is the capital of Japan and the largest city?\n","output_type":"stream"}]},{"cell_type":"code","source":"sequences = pipeline(\n    'What is the capital of japan?\\n',\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_length=257,\n)\n\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-29T15:37:33.737406Z","iopub.execute_input":"2024-04-29T15:37:33.737858Z","iopub.status.idle":"2024-04-29T15:37:50.990834Z","shell.execute_reply.started":"2024-04-29T15:37:33.737824Z","shell.execute_reply":"2024-04-29T15:37:50.989875Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Result: What is the capital of japan?\nWhat is the capital of jordan??\nWhat is the capital of korea??\nWhat is the capital of kosovo??\nWhat is the capital of kurdistan??\nWhat is the capital of kyrgyzstan??\nWhat is the capital of laos??\nWhat is the capital of lebanon??\nWhat is the capital of liberia??\nWhat is the capital of liberia??\nWhat is the capital of libya??\nWhat is the capital of liechtenstein??\nWhat is the capital of lithuania??\nWhat is the capital of luxembourg??\nWhat is the capital of macau??\nWhat is the capital of macedonia??\nWhat is the capital of madagascar??\nWhat is the capital of malawi??\nWhat is the capital of malaysia??\nWhat is the capital of maldives??\nWhat is the capital of mali??\nWhat is the capital of malta??\nWhat is the capital of marshall islands??\nWhat is the capital of martinique??\nWhat is the capital of mauretania??\nWhat is the capital of mauritius??\nWhat is the capital of mexico??\nWhat is the capital of micronesia?\n","output_type":"stream"}]},{"cell_type":"code","source":"# https://huggingface.co/blog/llama3\n\nimport transformers\nimport torch\n\nmodel = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n# model = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n\n# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\n# pipeline = transformers.pipeline(\n#     \"text-generation\",\n#     model=model_id,\n#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n#     device=\"cuda\",\n# )\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T16:43:22.640965Z","iopub.execute_input":"2024-04-29T16:43:22.641314Z","iopub.status.idle":"2024-04-29T16:45:28.452240Z","shell.execute_reply.started":"2024-04-29T16:43:22.641288Z","shell.execute_reply":"2024-04-29T16:45:28.451306Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-29 16:43:30.119859: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-29 16:43:30.119963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-29 16:43:30.274175: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7b50cf6b38408a89dc8dee0860024e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ndef extract(content):\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are a helpful chatbot. Extract the gender and the age of the author of the text provided by the user. Answer only when it is written explicitly, like \\\"I'm a 30 years old famale\\\", \\\"me (30F)\\\", \\\"my husband\\\", etc. If not written explicitly, say 'Unknown'. You don't need respond a complete sentence and no further information needed.\"},\n#         {\"role\": \"system\", \"content\": \"You are a helpful chatbot. Extract the gender and the age of the author of the text provided by the user. Answer only when it is written explicitly, like \\\"I'm a 30 years old famale\\\", \\\"me (30F)\\\", \\\"my husband\\\", etc. If not written explicitly, say 'Unknown'. Also, provide a part of the sentence you referred.\"},\n        {\"role\": \"user\", \"content\": content} \n    ]\n\n    prompt = pipeline.tokenizer.apply_chat_template(\n            messages, \n            tokenize=False, \n            add_generation_prompt=True\n    )\n\n    terminators = [\n        pipeline.tokenizer.eos_token_id,\n        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n    ]\n\n    outputs = pipeline(\n        prompt,\n        max_new_tokens=100,\n        eos_token_id=terminators,\n        do_sample=False,\n    #     do_sample=True,\n    #     top_k=10,\n    #     temperature=0.6,\n    #     top_p=0.9,\n    )\n    return outputs[0][\"generated_text\"][len(prompt):]\n","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:01:08.814242Z","iopub.execute_input":"2024-04-29T17:01:08.814982Z","iopub.status.idle":"2024-04-29T17:01:08.822838Z","shell.execute_reply.started":"2024-04-29T17:01:08.814950Z","shell.execute_reply":"2024-04-29T17:01:08.821902Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 7 µs, sys: 2 µs, total: 9 µs\nWall time: 14.8 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ncontents = [\n    # I'm a 21 year old female\n    \"Ok like I stated in the title I think I'm being an asshole. But there's this part of me that's perhaps irrationally pissed off at my boyfriend for this reason. \\n\\nI'm a 21 year old female and I'd been out with my boyfriend and a couple of his mates. We'd been at a bar and I have an 8am shift in the morning so I had to go to bed. My boyfriend however wanted to go pick up some booze and go to his mates for some more drinks - absolutely fine by me. \\n\\nSo I call a taxi to take me home and he asks me if I want him to stay with me. I say no its absolutely fine go get booze with your mates. He offered a couple of times and I said I'm absolutely fine just go. So he did. \\n\\nThen as I was stood alone in the street waiting for my taxi I realised I actually thought it was really shitty of him to leave me like that. And I know, I fucking SAID it was fine. I did. And that's why I think I'm the asshole. But.... A part of me just got annoyed he would actually leave me like that alone at night on the street. \\n\\nSo yeah I know I said it was fine, and this is the thing - I meant it at the time. I really did. I'm not one of those girls who plays mind games with guys (or at least I didn't think I was) and so when I said it it wasn't meant as some sort of fucking test.. I did mean it. But upon thinking about it I just feel like he should know it's not cool to leave a girl on her own at night like that? \\n\\nI text him about it but I feel like a dick. Does anyone want to confirm that for me?\",\n    # Me, 22M\n    \"So just some short context. Me, 22M, her, 20F.\\n\\nWe had a bit of a shouting match last night over getting the apartment cleaned up. I feel I shouldn't have to do as much as she's asking since I'm basically paying all the bills other than the internet/netflix bill, and I work 50+ hours a week.\\n\\nShe, consequently, only does nanny work occasionally as she can find it, so I only find it fair she should do most of the cleaning if she isn't working as often.\\n\\nI think I'm being pushed, when I'd expect her to do her fair share, considering I also do a lot of the dishes, vacuuming, laundry, etc. The least she can do is cook and clean if she isn't working.\\n\\nSo, who's the asshole here?\",\n    # my wife => male\n    \"Ok ill start with some background first. I recently have been dealing with quite a bit, being depressed and such. My mom hasnt talked to me in about 2 months, (we are normally really close ). Recently my wife and her had a falling out. Where my wife felt she was walking in and out of our life to much and didnt want it to effect our kids. My mom responded with a status about how were making the wrong decisions and we used them and everything else. Havent asked them for anything in quite awhile. I responded basically telling everyone on the fb thread to go fuck them selves for saying things like, they were to young to deal with kids thats why this is happening, that we are using our kids as pawns among other things. My main question is am i the asshole for responding. And did i do the right thing sticking up for my wife when i was caught in the middle? \\n\\nThis is the comment i made..... \\nTruthfully. This is nuts. Everyone is attacking everyone im fucking sick of it. Sharon you have been deleted off my page for about a year maybe more and on my wifes about 6 months. All of this shit should of stayed private. In the end friends dont come before family. Im sick of the bs. Children as pawns thats a joke. When your unable to leave your house because of money or other problems thats not my fault. I cant take being walked out on anymore. Anyone who is willing to call someone a child when they havent even met them, they are completely un informed nor should they be judging someone on how good of a parent they are.\\n\\nI understand i jumped around alot in that i responded to about 6 comments at once.\",\n    # unknown (suit => male?)\n    \"I work in an office that requires me to wear a suit all the time. I work more hours than everyone. Show up first, leave late, etc. The office has an air conditioning system which I turn on and set to 72º every morning. We don't run it at night. It's in New England and humid as fuck, so when you come in early, the place is dripping wet making it easy to feel uncomfortable at 70º when you always have to wear a coat and long pants. But after an hour of dehumidifying, 72º is fine. A co-worker of mine who only comes in once a week (and usually late) comes in dressed in designer clothes fit for going to the beach on a hot day and announces that it's too cold in here. I can't wear less and be dressed appropriately, and management isn't going to take the risk of criticizing a woman's fashion choices. I told her to wear a freaking sweater and left the AC on. \",\n    # unknown\n    \"I love the musical *Les Miserables*. A coworker of mine said that they didn't like it. I asked why and they said, among other things, that \\\"it's not a musical, it's an opera.\\\"\\n\\nNow, I happen to be an opera singer. I told them adamantly that it is NOT an opera. There are a number of things that make this true, but if you can take my word for it- and I hope you can- it's not a matter of opinion whether a mainstream musical is an opera or not. It is a musical, period.\\n\\nMy coworker thought otherwise. \\\"My boyfriend writes musicals and he agrees with me\\\" was the extent of her argument. Well, he may well write musicals but that doesn't mean he knows anything about opera. You might as well ask a jazz pianist to tell you about Beethoven- it's not the same area of expertise even if it's related. I told her \\\"You're entitled to your opinion even if it's wrong\\\" in a sort-of joking way. Maybe I was being dickish.\\n\\nI gotta know- am I the asshole?\"    ,\n]\n\nfor i, content in enumerate(contents):\n    print(i, extract(content))","metadata":{"execution":{"iopub.status.busy":"2024-04-29T17:01:09.411503Z","iopub.execute_input":"2024-04-29T17:01:09.411822Z","iopub.status.idle":"2024-04-29T17:01:12.703185Z","shell.execute_reply.started":"2024-04-29T17:01:09.411797Z","shell.execute_reply":"2024-04-29T17:01:12.702294Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"0 Female, 21 years old.\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"1 22M, 20F\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"2 M (Unknown)\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"3 F, Unknown\n4 Unknown\nCPU times: user 3.23 s, sys: 58.8 ms, total: 3.29 s\nWall time: 3.28 s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}